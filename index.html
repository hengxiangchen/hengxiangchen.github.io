<!DOCTYPE html>
<html lang="zh">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Hency | Robotics Research Assistant</title>
    <link rel="stylesheet" href="assets/css/styles.css" />
    <link
      href="https://fonts.googleapis.com/css2?family=Roboto+Mono&display=swap"
      rel="stylesheet"
    />
    <link
      rel="stylesheet"
      href="https://unpkg.com/@waline/client@v3/dist/waline.css"
    />
    <!-- ÂºïÂÖ• Ionicons CDN -->
    <script
      type="module"
      src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"
    ></script>
    <script
      nomodule
      src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"
    ></script>
  </head>

  <body>
    <!-- È°∂ÈÉ®ÂØºËà™Ê†è -->
    <header>
      <nav class="navbar">
        <div class="logo">Hency's Page</div>
        <ul class="nav-links">
          <li><a href="#intro">Intro</a></li>
          <li><a href="#projects">Selected Projects</a></li>
          <li><a href="#publications">Publications</a></li>
          <li><a href="#competitions">Competitions</a></li>
          <li><a href="#internship">Internship</a></li>
          <li><a href="#thesis">Thesis</a></li>
        </ul>
        <div class="menu-toggle" id="menu-toggle">
          <span class="bar"></span>
          <span class="bar"></span>
          <span class="bar"></span>
        </div>
      </nav>
    </header>

    <section>
      <div class="container">
        <!-- ‰∏™‰∫∫Á§æ‰∫§Â™í‰Ωì -->
        <div class="show-box" id="profile">
          <img src="assets/img/profile.jpeg" alt="Profile Picture" />

          <!-- Á§æ‰∫§ÈìæÊé• -->
          <div class="social-links">
            <a href="https://github.com/hency-727" target="_blank">
              <ion-icon
                name="logo-github"
                style="font-size: 40px; color: #000000"
              ></ion-icon>
            </a>
            <a
              href="https://wechat.com/your-wechat"
              target="_blank"
              id="wechat-link"
            >
              <svg
                xmlns="http://www.w3.org/2000/svg"
                width="40"
                height="40"
                fill="#000000"
                class="bi bi-wechat"
                viewBox="0 0 16 16"
              >
                <path
                  d="M11.176 14.429c-2.665 0-4.826-1.8-4.826-4.018 0-2.22 2.159-4.02 4.824-4.02S16 8.191 16 10.411c0 1.21-.65 2.301-1.666 3.036a.32.32 0 0 0-.12.366l.218.81a.6.6 0 0 1 .029.117.166.166 0 0 1-.162.162.2.2 0 0 1-.092-.03l-1.057-.61a.5.5 0 0 0-.256-.074.5.5 0 0 0-.142.021 5.7 5.7 0 0 1-1.576.22M9.064 9.542a.647.647 0 1 0 .557-1 .645.645 0 0 0-.646.647.6.6 0 0 0 .09.353Zm3.232.001a.646.646 0 1 0 .546-1 .645.645 0 0 0-.644.644.63.63 0 0 0 .098.356"
                />
                <path
                  d="M0 6.826c0 1.455.781 2.765 2.001 3.656a.385.385 0 0 1 .143.439l-.161.6-.1.373a.5.5 0 0 0-.032.14.19.19 0 0 0 .193.193q.06 0 .111-.029l1.268-.733a.6.6 0 0 1 .308-.088q.088 0 .171.025a6.8 6.8 0 0 0 1.625.26 4.5 4.5 0 0 1-.177-1.251c0-2.936 2.785-5.02 5.824-5.02l.15.002C10.587 3.429 8.392 2 5.796 2 2.596 2 0 4.16 0 6.826m4.632-1.555a.77.77 0 1 1-1.54 0 .77.77 0 0 1 1.54 0m3.875 0a.77.77 0 1 1-1.54 0 .77.77 0 0 1 1.54 0"
                />
              </svg>
            </a>
            <a href="mailto:hengxiangchen428@gmail.com" target="_blank">
              <ion-icon
                name="mail"
                style="font-size: 40px; color: #000000"
              ></ion-icon>
            </a>
          </div>

          <!-- Â∫ßÂè≥Èì≠ -->
          <div class="motto">
            <p>"Let robots do the dull, dirty, and dangerous."</p>
            <p>"È°ΩÂº∫ÁöÑÊµ∑Áõó‰ªé‰∏çÈúÄË¶ÅÁÅØÂ°î."</p>
          </div>
        </div>

        <!-- ÂºπÁ™ó -->
        <div id="wechat-modal" class="modal">
          <div class="modal-content">
            <div class="modal-header">
              <p>Scan QR Code to add my WeChat</p>
              <span id="close-modal">&times;</span>
            </div>
            <img src="assets/img/wechat_qrcode.png" alt="WeChat QR Code" />
          </div>
        </div>

        <!-- ‰∏™‰∫∫ÁÆÄ‰ªã -->
        <div class="show-box" id="intro">
          <h2>üßë‚ÄçüíºAbout Me</h2>
          <div class="inner-div">
            <ul>
              <li>I'm a research assistant in Robotics.</li>
              <h3 class="area-title">Education</h3>
              <li>
                Research Assistant at
                <a href="https://tusz-agdr.github.io/"
                  >Arbeit Gruppe Dexterous Robotics(AGDR) Lab, SZTU</a
                >, 09.2024 - present
              </li>
              <li>
                M.Phil. / Ph.D. (Full Scholarship)(Offer Accepted) in :
                <a href="https://www.hkust-gz.edu.cn/"
                  >HKUST(GZ)</a
                >, 09.2026
              </li>              
              <li>
                B.S. in Vehicle Engineering in:
                <a href="https://www.sztu.edu.cn/"
                  >Shenzhen Technology University(SZTU)</a
                >, 09.2021 - 06.2025
              </li>
              <li>
                Exchanged student at:
                <a href="https://www.hs-coburg.de/">Hochschule Coburg</a>,
                03.2024 - 08.2024
              </li>
              <li>
                Current Lab:
                <a href=""
                  ></a
                >, 09.2021 - present
              </li>
              <h3 class="area-title">Interests</h3>
              <span class="capsule-label green">Mobile Manipulation</span>
              <span class="capsule-label green">Robot Learning</span>
              <!-- <span class="capsule-label green">VLA</span> -->
            </ul>
            <br/>
            <a
              target="_blank"
              href="Resume-Latex-HengxiangChen/template.pdf"
              class="button green">
              <ion-icon name="save" style="font-size: 20px"></ion-icon>
              &ensp;Download CV
            </a>
          </div>
        </div>

        <!-- È°πÁõÆÂ±ïÁ§∫ -->
        <div class="show-box" id="projects">
          <h2>üõ†Ô∏èSelected Projects</h2>
          <div id="video-player">
            <video id="main-video" controls>
              <source src="" type="video/mp4" />
              Your browser does not support the video tag.
            </video>
          </div>

          <div id="thumbnails">
            <button
              class="thumb active"
              onclick="selectVideo(0)"
              alt="Video 1"
            ></button>
            <button
              class="thumb"
              onclick="selectVideo(1)"
              alt="Video 2"
            ></button>
            <button
              class="thumb"
              onclick="selectVideo(2)"
              alt="Video 3"
            ></button>
            <button
              class="thumb"
              onclick="selectVideo(3)"
              alt="Video 4"
            ></button>
          </div>
        </div>

        <!-- ËØÅ‰π¶Â±ïÁ§∫ -->
        <div class="show-box" id="publications">
          <h2>üìöPublications</h2>
          <div class="carousel-container">
            <div class="carousel-wrapper">
              <div class="carousel-item">
                <img
                  src="assets/img/publications/Path_Planning_Algorithm_Comparison_Analysis_for_Wireless_AUVs_Energy_Sharing_System.png"
                  alt="Path Planning Algorithm Comparison Analysis for Wireless AUVs Energy Sharing System"
                />
                <div class="carousel-text">
                  <p class="title">
                    Path Planning Algorithm Comparison Analysis for Wireless
                    AUVs Energy Sharing System
                  </p>
                  <p class="text">
                    In this research, we proposes a wireless AUV energy sharing
                    system for underwater recharging, focuses on path planning
                    to navigate from supplier AUV to consumer AUV in complex
                    underwater environments, we evaluate and compare path
                    length„ÄÅenergy consumption and time/space complexity of RRT*
                    and PSO algorithms under different scenarios (static
                    obstacles and dynamic obstacles„ÄÅcommon conditions and
                    narrow area).
                  </p>
                  <a
                    href="https://github.com/Hency-727/Algorithm_Comparison_RRTstar_and_PSO"
                    >View on GitHub</a
                  ><br />
                  <a href="https://arxiv.org/abs/2203.03092">Paper Address</a>
                </div>
              </div>
              <div class="carousel-item">
                <img
                  src="assets/img/publications/Cross-Modal_Robotic_Perception_for-poster.png"
                  alt="Cross-Modal Robotic Perception for poster"
                />
                <div class="carousel-text">
                  <p class="title">
                    Cross Modal Robotic Perception with a Large Vision Language
                    Model for Physical Property Inference
                  </p>
                  <p class="text">
                    Inferring physical properties can significantly enhance
                    robotic manipulation by enabling robots to handle objects
                    safely and efficiently through adaptive grasping strategies.
                    However, previous approaches have typically relied solely on
                    either tactile or visual data, limiting their ability to
                    fully capture object properties. In this work, we propose a
                    novel cross-modal perception framework that integrates
                    visual observations with tactile representations within a
                    multimodal vision-language model. Our physical reasoning
                    framework incorporates a hierarchical feature alignment
                    mechanism and a refined prompting strategy, enabling
                    property-specific predictions that correlate strongly with
                    ground-truth physical measurements. We evaluate our approach
                    on a dataset comprising 30 diverse objects and demonstrate
                    that it outperforms existing baselines in accurately
                    predicting physical properties critical for robotic
                    manipulation.
                  </p>
                  <a href="https://github.com/hency/robonav">View on GitHub</a>
                </div>
              </div>
            </div>
            <div class="prev" onclick="moveSlide(-1, 'publications')">
              &#10094;
            </div>
            <div class="next" onclick="moveSlide(1, 'publications')">
              &#10095;
            </div>
          </div>
        </div>

        <!-- ÊØîË≥ΩÂ±ïÁ§∫ -->
        <div class="show-box" id="competitions">
          <h2>üèÜCompetitions</h2>
          <div class="carousel-container">
            <div class="carousel-wrapper">
              <div class="carousel-item">
                <img
                  src="assets/img/certificates/17th_ROS_outdoor_competition.png"
                  alt="17th ROS outdoor competition"
                />
                <div class="carousel-text">
                  <p class="title">
                    3rd place in the outdoor ROS competition of the 17th
                    National College Student Smart Car Competition
                  </p>
                  <p class="text">
                    The race track is delineated by red and blue cones marking
                    the left and right boundaries. The competition requires
                    completing the first lap through autonomous mapping,
                    followed by a second lap involving autonomous navigation in
                    the shortest possible time. Our solution utilized a
                    comprehensive technology stack, including high-level chassis
                    controller design, multi-modal data fusion of vision and
                    radar for obstacle detection, map optimization, and
                    autonomous localization and navigation tracking.
                  </p>
                  <a
                    href="https://github.com/Hency-727/racecar_outdoor_ros_competition2022"
                    >View on GitHub</a
                  ><br />
                </div>
              </div>
              <div class="carousel-item">
                <img
                  src="assets/img/certificates/25th_Competition_(Intelligent_Driving).png"
                  alt="25th Competition (Intelligent Driving)"
                />
                <div class="carousel-text">
                  <p class="title">
                    5th place in the 25th China Robotics and Artificial
                    Intelligence Competition
                  </p>
                  <p class="text">
                    Developed a robot navigation system capable of reaching
                    specified target points in minimal time within a closed
                    environment, handling narrow corridors and complex discrete
                    scenarios (e.g., double figure-eight turns formed by cone
                    markers) using Ackermann steering chassis. Employed Gmapping
                    for SLAM-based environment mapping, AMCL for localization,
                    and MoveBase for path planning.Implemented a Pure Pursuit
                    (PP) algorithm for real-time target point tracking and path
                    following.
                  </p>
                  <a
                    href="https://github.com/Hency-727/racecar_intelligent_driving2023"
                    >View on GitHub</a
                  >
                </div>
              </div>
              <div class="carousel-item">
                <img
                  src="assets/img/certificates/18th_Design_Competition.png"
                  alt="18th Design Competition"
                />
                <div class="carousel-text">
                  <p class="title">
                    3rd Prize in the National College Students Intelligent Car
                    Competition Intelligent Car Creative Design Competition
                  </p>
                  <p class="text">
                    This project was developed by the "È°∂Â≥∞Áõ∏ËßÅÔºåÈ£éÂÖâÊó†Èôê" team
                    from Shenzhen Technology University as part of the 2023
                    National College Student Smart Car Competition. Built upon
                    the official competition chassis, the team focused on
                    optimizing vehicle structure, sensor layout, and control
                    logic design to create a dual-mode intelligent concept car
                    that balances functionality and aesthetic expression.
                  </p>
                  <a href="https://github.com/hency/robonav">View on GitHub</a>
                </div>
              </div>
            </div>
            <div class="prev" onclick="moveSlide(-1, 'competitions')">
              &#10094;
            </div>
            <div class="next" onclick="moveSlide(1, 'competitions')">
              &#10095;
            </div>
          </div>
        </div>

        <!-- ÂÆû‰π†ËØÅÊòé -->
        <div class="show-box" id="internship">
          <h2>üíºInternship Report</h2>
          <div class="carousel-container">
            <div class="carousel-wrapper">
              <div class="carousel-item">
                <img
                  src="assets/img/The_impact_of_latency_and_vehicle_speed_on_the_motion_control_of_remote_urban_driving.jpg"
                  alt="The impact of latency and vehicle speed on the motion control of remote urban driving"
                />
                <div class="carousel-text">
                  <p class="title">
                    The impact of latency and vehicle speed on the motion
                    control of remote urban driving
                  </p>
                  <p class="text">
                    In this research, we quantitatively analyzes the impacts of
                    latency and vehicle speed on motion control in remote urban
                    driving through statistical modeling of simulation results
                    and real-world vehicle data. It employs Time To Collision
                    (TTC) as a collision risk metric to evaluate and quantify
                    the risk associated with different latency scenarios.
                    Experimental results indicate that higher latency
                    significantly increases collision risks in specific traffic
                    scenarios, such as protected left turns and intersections.
                    The study proposes practical safety countermeasures,
                    including scenario restrictions, speed optimization, and
                    local Automated Emergency Braking (AEB), providing critical
                    insights to improve the safety and reliability of remote
                    driving systems.
                  </p>
                </div>
              </div>
            </div>
            <!-- <div class="prev" onclick="moveSlide(-1, 'internship')">
              &#10094;
            </div>
            <div class="next" onclick="moveSlide(1, 'internship')">
              &#10095;
            </div> -->
          </div>
        </div>

        <!-- ÊØï‰∏öËÆ∫Êñá -->
        <div class="show-box" id="thesis">
          <h2>üéìGraduated Paper</h2>
          <div class="carousel-container">
            <div class="carousel-wrapper">
              <div class="carousel-item">
                <img
                  src="assets/img/bachelor_thesis_cover.png"
                  alt="Vision-Touch Guided Grasping for Mobile Manipulators control of remote urban driving"
                />
                <div class="carousel-text">
                  <p class="title">
                    Vision-Touch Guided Grasping for Mobile Manipulators control
                    of remote urban driving
                  </p>
                  <p class="text">
                    Problem: Mobile manipulators often struggle with accurate
                    object grasping and long-range navigation in semantically
                    rich, dynamic environments. Approach: Designed a full-stack
                    robotic system combining Cartographer for high-precision
                    localization and GraspNet-based 6-DoF grasp pose prediction
                    under RGB-D Realsense D455i and tactile sensor (Gelsight
                    Mini). Built a ROS-based pipeline integrating YOLOv8 for
                    object detection, SAM for segmentation, and MoveIt for
                    motion planning.</p>
                    <p class="text">Outcome: The localization accuracy was
                    verified through qualitative and quantitative experiments,
                    and crossing-navigation and object grasping in different
                    scenarios were realized.
                  </p>
                </div>
              </div>
            </div>
            <!-- <div class="prev" onclick="moveSlide(-1, 'thesis')">
              &#10094;
            </div>
            <div class="next" onclick="moveSlide(1, 'thesis')">
              &#10095;
            </div> -->
          </div>
        </div>

        <!-- ËØÑËÆ∫Âå∫ - Waline -->
        <div id="waline"></div>
      </div>
    </section>

    <footer>
      <p>&copy; 2025 Hency. All rights reserved.</p>
    </footer>

    <script src="assets/js/script.js"></script>
    <script>
      // ÂàùÂßãÂåñÈªòËÆ§ËßÜÈ¢ë
      document.querySelector("#main-video source").src = selectVideo(0);
    </script>
    <script type="module">
      import { init } from "https://unpkg.com/@waline/client@v3/dist/waline.js";

      init({
        el: "#waline",
        serverURL: "https://walinehency.vercel.app",
      });
    </script>
  </body>
</html>
